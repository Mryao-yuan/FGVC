{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from numpy import repeat\n",
    "from einops import rearrange\n",
    "import torch\n",
    "from torch import einsum\n",
    "\n",
    "'''\n",
    "# 转置，对角线对称\n",
    "image = rearrange(image, 'h w c -> w h c')\n",
    "# 计算矩阵的迹\n",
    "a = torch.ones(3,4)\n",
    "einsum('ii',a)\n",
    "# 计算你在所有元素的和\n",
    "einsum('i,j',a)\n",
    "\n",
    "'''\n",
    "def pair(size):\n",
    "    if(type(size) !=(size,size)):\n",
    "        return (size,size)\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    '''\n",
    "    标准化，设置可传入参数(Multi-Head Attention 和 MLP)\n",
    "    '''\n",
    "    def __init__(self,dim,fn) -> None:\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNopprm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self,x,**kwargs):\n",
    "        return self.fn(self.norm(x),**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    # 默认 8 个头，每个头处理64维的信息，用于计算注意力的维度为512维\n",
    "    def __init__(self,dim,heads=8,dim_head=64,dropout=0.) -> None:\n",
    "        super().__init__()\n",
    "        # 计算注意力的维度\n",
    "        inner_dim = dim_head *heads\n",
    "        project_out = not(heads ==1 and dim_head==dim)\n",
    "        \n",
    "        self.heads = heads\n",
    "        self.scale = dim_head **-0.5\n",
    "        # 将输出的最后一维归一化\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.to_qkv = nn.Linear(dim,inner_dim*3,bias=False)\n",
    "        self.to_out = nn.Sequemtial(\n",
    "            nn.Linear(inner_dim,dim),\n",
    "            nn.Droupout(dropout),\n",
    "        )if project_out else nn.Identify()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        b,n,_,h = *x.shape,self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3,dim=-1)\n",
    "        \n",
    "        q,k,v =map(lambda t: rearrange(t,'b n (h d) -> b h n d', h=h), qkv)\n",
    "        \n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        attn = self.attend(dots)\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        \n",
    "        # 这一步是将每一个头输出的Attention向量拼接起来，将多头输出变成一个输出，可以看到将h隐藏了起来\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim), \n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class transformer(nn.Module):\n",
    "    '''\n",
    "       dim:输入的最后一维\n",
    "        depth:transformer中多头注意力层(Attention层)的层数\n",
    "        heads:多头注意力头数\n",
    "        dim_head:多头注意力层的输入(与dim区别)\n",
    "        mlp_dim:mlp层隐藏层的维度\n",
    "        droupout:失活神经元的比例\n",
    "    '''\n",
    "    def __init__(self,dim,depth,heads,dim_head,mlp_dim,dropout=0.) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.Modulelist([])\n",
    "        for _ in range(depth):\n",
    "            self.layer.append(nn.Modulelist([\n",
    "                PreNorm(dim,Attention(dim,))\n",
    "            ]))\n",
    "    def forward(self,x):\n",
    "        for attn,ff in self.layers:\n",
    "            x = attn(x)+x\n",
    "            x = ff(x)+x\n",
    "            return x\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self,*,image_size,patch_size,num_classes,dim,depth,heads,mlp_dim, \\\n",
    "        pool='cls', channels=1, dim_head=64, dropout=0., emb_dropout=0.):\n",
    "        super().__init__()\n",
    "        # 图片patch化\n",
    "        image_height,image_width = pair(image_size)\n",
    "        patch_height,patch_width = pair(patch_size)\n",
    "        # 保证 图片的大小和patch的长宽可以整除\n",
    "        assert image_height % patch_height ==0 and image_width % patch_width ==0 \n",
    "        num_patches = (image_height//patch_height)*(image_width//patch_width)\n",
    "        patch_dim = channels *patch_height*patch_width\n",
    "        \n",
    "        assert pool in {'cls','mean'}\n",
    "        \n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            rearrange('b c (h p1)(w p2) -> b (h w)(p1 p2 c)',p1=patch_height,p2=patch_width),\n",
    "            nn.Linear(patch_dim,dim)\n",
    "        )\n",
    "        # 初始化 cls_token\n",
    "        # nn.Parameter() 定义可学习参数\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1,dim))\n",
    "        # 初始化位置信息\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1,num_patches+1,dim))\n",
    "        \n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "        \n",
    "        # 初始化 transformer\n",
    "        self.transformer = transformer(dim,depth,heads,dim_head,mlp_dim,dropout)\n",
    "        \n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim,num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,img):\n",
    "        # 图片patche 化\n",
    "        # [b,c,(h*p1),(w*p2)] -> [b,(h*w),(p1*p2*c)] -> [b,(h*w),dim]\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b,n,_ = x.shape()\n",
    "        \n",
    "        cls_tokens = repeat(self.cls_token,'() n d -> b n d',b=b)\n",
    "        \n",
    "        x = torch.cat((cls_tokens,x),dim=1)\n",
    "        x += self.pos_embedding[:,:(n+1)]\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1) if self.pool=='mean' else x[:,0]\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ViT train [--opts OPTS [OPTS ...]] [--batch-size BATCH_SIZE]\n",
      "                 [--data-path DATA_PATH] [--epoch EPOCH] [--lr LR]\n",
      "ViT train: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9003 --control=9001 --hb=9000 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"e86de039-ac7e-43fe-8c63-531f9dbb6dcf\" --shell=9002 --transport=\"tcp\" --iopub=9004 --f=/home/yy/.local/share/jupyter/runtime/kernel-v2-44453S9WSNtQSaqnt.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yy/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3386: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# 参数配置\n",
    "import argparse\n",
    "import torch.optim as op\n",
    "import yaml\n",
    "\n",
    "'''yaml?\n",
    "\n",
    "\n",
    "'''\n",
    "'''\n",
    "_C = CN()\n",
    "\n",
    "# Base config files\n",
    "_C.BASE = ['']\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Data settings\n",
    "# -----------------------------------------------------------------------------\n",
    "_C.DATA = CN()\n",
    "# Batch size for a single GPU, could be overwritten by command line argument\n",
    "_C.DATA.BATCH_SIZE = 32\n",
    "# Path to dataset, could be overwritten by command line argument\n",
    "_C.DATA.DATA_PATH = ''\n",
    "# Dataset name\n",
    "_C.DATA.DATASET = 'imagenet'\n",
    "# Input image size\n",
    "_C.DATA.IMG_SIZE = 224\n",
    "def _update_config_from_file(config, cfg_file):\n",
    "    config.defrost()\n",
    "    with open(cfg_file, 'r') as f:\n",
    "        yaml_cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    for cfg in yaml_cfg.setdefault('BASE', ['']):\n",
    "        if cfg:\n",
    "            _update_config_from_file(\n",
    "                config, os.path.join(os.path.dirname(cfg_file), cfg)\n",
    "            )\n",
    "    print('=> merge config from {}'.format(cfg_file))\n",
    "    config.merge_from_file(cfg_file)\n",
    "    config.freeze()\n",
    "\n",
    "def update_config(config, args):\n",
    "    _update_config_from_file(config, args.cfg)\n",
    "\n",
    "    config.defrost()\n",
    "    if args.opts:\n",
    "        config.merge_from_list(args.opts)\n",
    "\n",
    "    # merge from specific arguments\n",
    "    if args.batch_size:\n",
    "        config.DATA.BATCH_SIZE = args.batch_size\n",
    "    if args.data_path:\n",
    "        config.DATA.DATA_PATH = args.data_path\n",
    "    if args.zip:\n",
    "        config.DATA.ZIP_MODE = True\n",
    "    if args.cache_mode:\n",
    "        config.DATA.CACHE_MODE = args.cache_mode\n",
    "    if args.resume:\n",
    "        config.MODEL.RESUME = args.resume\n",
    "    if args.accumulation_steps:\n",
    "        config.TRAIN.ACCUMULATION_STEPS = args.accumulation_steps\n",
    "    if args.use_checkpoint:\n",
    "        config.TRAIN.USE_CHECKPOINT = True\n",
    "    if args.amp_opt_level:\n",
    "        config.AMP_OPT_LEVEL = args.amp_opt_level\n",
    "    if args.output:\n",
    "        config.OUTPUT = args.output\n",
    "    if args.tag:\n",
    "        config.TAG = args.tag\n",
    "    if args.eval:\n",
    "        config.EVAL_MODE = True\n",
    "    if args.throughput:\n",
    "        config.THROUGHPUT_MODE = True\n",
    "\n",
    "        \n",
    "    if args.num_workers is not None:\n",
    "        config.DATA.NUM_WORKERS = args.num_workers\n",
    "        \n",
    "    #set lr and weight decay\n",
    "    if args.lr is not None:\n",
    "        config.TRAIN.BASE_LR = args.lr\n",
    "    if args.min_lr is not None:\n",
    "        config.TRAIN.MIN_LR = args.min_lr\n",
    "    if args.warmup_lr is not None:\n",
    "        config.TRAIN.WARMUP_LR = args.warmup_lr\n",
    "    if args.warmup_epochs is not None:\n",
    "        config.TRAIN.WARMUP_EPOCHS = args.warmup_epochs\n",
    "    if args.weight_decay is not None:\n",
    "        config.TRAIN.WEIGHT_DECAY = args.weight_decay\n",
    "\n",
    "    if args.epochs is not None:\n",
    "        config.TRAIN.EPOCHS = args.epochs\n",
    "    if args.dataset is not None:\n",
    "        config.DATA.DATASET = args.dataset\n",
    "    if args.lr_scheduler_name is not None:\n",
    "        config.TRAIN.LR_SCHEDULER.NAME = args.lr_scheduler_name\n",
    "    if args.pretrain is not None:\n",
    "        config.MODEL.PRETRAINED = args.pretrain\n",
    "\n",
    "    # set local rank for distributed training\n",
    "    config.LOCAL_RANK = args.local_rank\n",
    "\n",
    "    # output folder\n",
    "    config.OUTPUT = os.path.join(config.OUTPUT, config.MODEL.NAME, config.TAG)\n",
    "\n",
    "    config.freeze()\n",
    "\n",
    "def get_config(args):\n",
    "    \"\"\"Get a yacs CfgNode object with default values.\"\"\"\n",
    "    # Return a clone so that the defaults will not be altered\n",
    "    # This is for the \"local variable\" use pattern\n",
    "    config = _C.clone()\n",
    "    update_config(config, args)\n",
    "\n",
    "    return config\n",
    "def parse_option():\n",
    "    # ArgumentParser 将命令行和解析成Python数据类型所需的全部信息\n",
    "    parser = argparse.ArgumentParser('ViT train', add_help=False)\n",
    "    # add_argument 添加参数信息\n",
    "    #parser.add_argument('--cfg', type=str, required=True, metavar=\"FILE\", help='path to config file', )\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
    "        default=None,\n",
    "        nargs='+',\n",
    "    )\n",
    "     # easy config modification\n",
    "    parser.add_argument('--batch-size', default=32,type=int, help=\"batch size for single GPU\")\n",
    "    parser.add_argument('--data-path',default='/home/yy/Project/dataset/data', type=str, help='path to dataset')\n",
    "    parser.add_argument('--epoch',default=250, type=int, help='path to dataset')\n",
    "    parser.add_argument('--lr',default=1e-4, type=float, help='learning rate')\n",
    "   # parser.add_argument('--optim',default=op.Adam,type=)\n",
    "    # 设置\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "'''\n",
    "def parse_option():\n",
    "    # ArgumentParser 将命令行和解析成Python数据类型所需的全部信息\n",
    "    parser = argparse.ArgumentParser('ViT train', add_help=False)\n",
    "    # add_argument 添加参数信息\n",
    "    #parser.add_argument('--cfg', type=str, required=True, metavar=\"FILE\", help='path to config file', )\n",
    "    parser.add_argument(\n",
    "        \"--opts\",\n",
    "        help=\"Modify config options by adding 'KEY VALUE' pairs. \",\n",
    "        default=None,\n",
    "        nargs='+',\n",
    "    )\n",
    "     # easy config modification\n",
    "    parser.add_argument('--batch-size', default=32,type=int, help=\"batch size for single GPU\")\n",
    "    parser.add_argument('--data-path',default='/home/yy/Project/dataset/data', type=str, help='path to dataset')\n",
    "    parser.add_argument('--epoch',default=250, type=int, help='path to dataset')\n",
    "    parser.add_argument('--lr',default=1e-4, type=float, help='learning rate')\n",
    "   # parser.add_argument('--optim',default=op.Adam,type=)\n",
    "    # 将参数设置为元组形式返回\n",
    "    args = parser.parse_known_args()\n",
    "   \n",
    "    \n",
    "    print(type(args))\n",
    "    print(args)\n",
    "parse_option()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yacs的学习\n",
    "\n",
    "yacs是一个轻量级用于管理系统配置的开源库，常用于模型训练过程中的参数配置(lr,depth...),使用可读的yaml格式。\n",
    "\n",
    "**安装**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yacs in /home/yy/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML in /home/yy/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages (from yacs) (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install yacs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**yacs的使用**\n",
    "\n",
    "1. 新建一个`config.yaml`文件\n",
    "    ```yaml\n",
    "    DATA:\n",
    "        IMG_SIZE: 224\n",
    "    MODEL:\n",
    "        TYPE: MetaFG\n",
    "        NAME: MetaFG_0\n",
    "    ```\n",
    "2. 新建`python`文件\n",
    "\n",
    "    ```python\n",
    "    import os\n",
    "    import yaml\n",
    "    from yacs.config import CfgNode as CN  \n",
    "    \n",
    "     \n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "训练数据集长度为50000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m inputs ,lables \u001b[39m=\u001b[39m data\n\u001b[1;32m     23\u001b[0m inputs,lables \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device),lables\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[39m=\u001b[39m ViT(inputs)\n\u001b[1;32m     25\u001b[0m _,predict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata,\u001b[39m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m predict\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as tf\n",
    "import  torch\n",
    "\n",
    "trans_train = torchvision.transforms.Compose([\n",
    "    tf.ToTensor(),\n",
    "])\n",
    "traindata = torchvision.datasets.CIFAR10('/home/yy/Project/dataset/data',train=True,transform=trans_train,\n",
    "                                          download=True)\n",
    "\n",
    "train_data_size = len(traindata)\n",
    "print('训练数据集长度为{}'.format(train_data_size))\n",
    "# 加载数据集\n",
    "dataloader = torch.utils.data.DataLoader(traindata,batch_size=32)\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "epoch = 30\n",
    "total =0\n",
    "predict_correct = 0.0\n",
    "for i in range(epoch):\n",
    "    \n",
    "    for data in dataloader:\n",
    "        inputs ,lables = data\n",
    "        inputs,lables = inputs.to(device),lables.to(device)\n",
    "        outputs = ViT(inputs)\n",
    "        _,predict = torch.max(outputs.data,1)\n",
    "        total += predict.size(0)\n",
    "        predict_correct +=(predict==lables).sum()\n",
    "        \n",
    "    print('[epoch { },accuracy {}]'.format(epoch+1,predict_correct/total))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 知识点\n",
    "\n",
    "`*`和`**`的区别与应用\n",
    "- `*`:接受元组对象中的每个元素，然后作为一个个的**位置参数**传入函数中\n",
    "- `**`:接收字典对象中的每个元素，作为一个个的**关键字参数**传入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "{'name': '张三', 'age': 21, 'score': 100}\n"
     ]
    }
   ],
   "source": [
    "def fun1(*args):\n",
    "    print(*args)\n",
    "def fun2(**kwargs):\n",
    "    print(kwargs)\n",
    "fun1(\"1\",\"2\",\"3\")\n",
    "fun2(name=\"张三\",age=21,score=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "620e0971fdfedb47815252a730f9c9fc24e1c5eb66f4c856afd7a9506a291b64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
