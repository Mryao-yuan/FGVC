{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yy/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-16 14:30:16.350502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-16 14:30:16.765949: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-16 14:30:16.905898: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-16 14:30:17.869800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: 无法打开共享对象文件: 没有那个文件或目录\n",
      "2022-11-16 14:30:17.869888: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: 无法打开共享对象文件: 没有那个文件或目录\n",
      "2022-11-16 14:30:17.869896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "# 通道注意力\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_planes, ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        # MLP\n",
    "        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "\n",
    "# 空间注意力\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)    # 1*H*W\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)  # 1*H*W torch.max返回 value，indice\n",
    "        x = torch.cat([avg_out, max_out], dim=1)        # 将 全局池化和全局平均的值进行cat\n",
    "        x = self.conv1(x)                               # 通过 7*7 的卷积\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.ca = ChannelAttention(planes)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        # 先通道后空间\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.ca = ChannelAttention(planes * 4)\n",
    "        self.sa = SpatialAttention()\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        out = self.ca(out) * out\n",
    "        out = self.sa(out) * out\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "pretrain_rest18_path = '/home/yy/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth'   \n",
    "\n",
    "def resnet18_cbam(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        pretrained_state_dict = torch.load(pretrain_rest18_path) # 载入预训练的权重文件\n",
    "        now_state_dict = model.state_dict()                      # 获取模型的字典   \n",
    "        now_state_dict.update(pretrained_state_dict)             # 模型更新权重   \n",
    "        model.load_state_dict(now_state_dict)                    # 模型载入权重\n",
    "    return model\n",
    "\n",
    "\n",
    "model = resnet18_cbam(True) \n",
    "\n",
    "input = torch.ones(size=(1,3,224,224))\n",
    "\n",
    "writer = SummaryWriter('./log')\n",
    "writer.add_graph(model,input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "tensor([[[-0.9303,  1.1809,  0.6511,  0.2058],\n",
      "         [ 0.9055,  0.3907,  1.7731,  0.9095],\n",
      "         [ 1.7692,  1.4200,  1.0895, -1.1496]],\n",
      "\n",
      "        [[-1.3400, -0.4275,  0.4963,  0.8290],\n",
      "         [ 0.9121,  0.5678, -0.3035,  0.7892],\n",
      "         [ 2.5693, -0.7547, -0.0259, -1.6931]]])\n",
      "torch.return_types.max(\n",
      "values=tensor([[[1.7692, 1.4200, 1.7731, 0.9095]],\n",
      "\n",
      "        [[2.5693, 0.5678, 0.4963, 0.8290]]]),\n",
      "indices=tensor([[[2, 2, 1, 1]],\n",
      "\n",
      "        [[2, 1, 0, 0]]]))\n",
      "KeepMid = False\n",
      "torch.return_types.max(\n",
      "values=tensor([[1.7692, 1.4200, 1.7731, 0.9095],\n",
      "        [2.5693, 0.5678, 0.4963, 0.8290]]),\n",
      "indices=tensor([[2, 2, 1, 1],\n",
      "        [2, 1, 0, 0]]))\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((2,3,4))\n",
    "print(x.shape)\n",
    "print(x)\n",
    "print(torch.max(x,dim=1,keepdim=True))\n",
    "print('KeepMid = False')\n",
    "print(torch.max(x,dim=1,keepdim=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (ca): ChannelAttention(\n",
      "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
      "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
      "        (fc): Sequential(\n",
      "          (0): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): ReLU()\n",
      "          (2): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        )\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "      (sa): SpatialAttention(\n",
      "        (conv1): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "        (sigmoid): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 torch.Size([1, 1024, 1, 1])\n",
      "w1 torch.Size([1, 1024, 1, 1])\n",
      "torch.Size([1, 1024, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class CBAMlayer(nn.Module):\n",
    "    def __init__(self,inchannel,reduction,spatial_kernel=7):\n",
    "        super(CBAMlayer,self).__init__()\n",
    "        \n",
    "        # channel attention\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Conv2d(inchannel,inchannel//reduction,1,bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inchannel//reduction,inchannel,1,bias=False),\n",
    "        )\n",
    "        \n",
    "        # spatial attention\n",
    "        self.conv = nn.Conv2d(2,1,kernel_size=spatial_kernel,padding=spatial_kernel//2,bias=False) # 输入通道为2是因为将空间的最大池化和平均池化后的通道为 2 \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # channeltion attention\n",
    "        # print('w0',self.max_pool(x).shape)\n",
    "        max_out = self.mlp(self.max_pool(x)) # c*1*1\n",
    "        # print('w1',max_out.shape)\n",
    "        avg_out = self.mlp(self.avg_pool(x)) # c*1*1\n",
    "        channel_out = self.sigmoid(max_out+avg_out)\n",
    "        x = channel_out * x # c*h*w\n",
    "        # spatial attrntion\n",
    "        max_spatial_out,_ = torch.max(x,dim=1,keepdim=True) # 保持维度不变,对通道上求值 1*h*w\n",
    "        # print('max_spatial_shape',max_spatial_out.shape)\n",
    "        avg_spatial_out =  torch.mean(x,dim=1,keepdim=True) # 保持维度不变\n",
    "        spatial_out = self.sigmoid(self.conv(torch.cat([max_spatial_out,avg_spatial_out],dim=1))) # 第二维上叠加\n",
    "        \n",
    "        return x*spatial_out        # c*h*w\n",
    "    \n",
    "x = torch.randn(1,1024,32,32)\n",
    "net = CBAMlayer(inchannel=1024,reduction=16)\n",
    "y = net.forward(x)\n",
    "print(y.shape)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp.0.weight torch.Size([64, 1024, 1, 1])\n",
      "mlp.2.weight torch.Size([1024, 64, 1, 1])\n",
      "conv.weight torch.Size([1, 2, 7, 7])\n",
      "OrderedDict([('max_pool', AdaptiveMaxPool2d(output_size=1)), ('avg_pool', AdaptiveAvgPool2d(output_size=1)), ('mlp', Sequential(\n",
      "  (0): Conv2d(1024, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      ")), ('conv', Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)), ('sigmoid', Sigmoid())])\n"
     ]
    }
   ],
   "source": [
    "for name,param in net.named_parameters():\n",
    "    print(name,param.size())\n",
    "\n",
    "# 输出查看子模块 \n",
    "print(net._modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1606, -1.0392,  0.9616],\n",
       "         [ 1.0680,  0.4330,  0.3037]]),\n",
       " tensor([[ 0.3501, -0.0134,  0.3454],\n",
       "         [-0.8049, -0.7044, -0.2703]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3)\n",
    "y = torch.randn(2,3)\n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1606, -1.0392,  0.9616],\n",
      "        [ 1.0680,  0.4330,  0.3037],\n",
      "        [ 0.3501, -0.0134,  0.3454],\n",
      "        [-0.8049, -0.7044, -0.2703]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "cat_dim_0 = torch.cat([x,y],dim=0)\n",
    "print(cat_dim_0)\n",
    "print(cat_dim_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1606, -1.0392,  0.9616,  0.3501, -0.0134,  0.3454],\n",
      "        [ 1.0680,  0.4330,  0.3037, -0.8049, -0.7044, -0.2703]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([x,y],dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力机制之通道注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# SEnet\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mSEnet\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n\u001b[1;32m      3\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,channel,reduction\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m):\n\u001b[1;32m      4\u001b[0m         \u001b[39msuper\u001b[39m(SEnet, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# SEnet\n",
    "class SEnet(nn.Module):\n",
    "    def __init__(self,channel,reduction=16):\n",
    "        super(SEnet, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel,channel//reduction,bias=False),\n",
    "            nn.ReLU(inpale=True),\n",
    "            nn.Linear(channel//reduction,channel,bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # Batch,Channel ,Height,Width\n",
    "        b,c,_,_ = x.size()\n",
    "        y = self.avg_pool(x).view(b,c) # 宽高为1\n",
    "        y= self.fc(y).view(b,c,1,1)\n",
    "        \n",
    "        return x*y.expand_as(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "# from .MPNCOV.python import MPNCOV\n",
    "import pdb\n",
    "\n",
    "__all__ = ['ResNet', 'resnet50', 'resnet101']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def cov_feature(x):\n",
    "    batchsize = x.data.shape[0]\n",
    "    dim = x.data.shape[1]\n",
    "    h = x.data.shape[2]\n",
    "    w = x.data.shape[3]\n",
    "    M = h*w\n",
    "    x = x.reshape(batchsize,dim,M)\n",
    "    I_hat = (-1./M/M)*torch.ones(dim,dim,device = x.device) + (1./M)*torch.eye(dim,dim,device = x.device)\n",
    "    I_hat = I_hat.view(1,dim,dim).repeat(batchsize,1,1).type(x.dtype)\n",
    "    y = (x.transpose(1,2)).bmm(I_hat).bmm(x)\n",
    "    return y\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, attention='0', att_dim=128):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.dimDR = att_dim\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.relu_normal = nn.ReLU(inplace=False)\n",
    "        if attention in {'1','+','M','&'}:\n",
    "            if planes > 64:\n",
    "                DR_stride=1\n",
    "            else:\n",
    "                DR_stride=2\n",
    "\n",
    "            self.ch_dim = att_dim\n",
    "            self.conv_for_DR = nn.Conv2d(\n",
    "                 planes * self.expansion, self.ch_dim, \n",
    "                 kernel_size=1,stride=DR_stride, bias=True)\n",
    "            self.bn_for_DR = nn.BatchNorm2d(self.ch_dim)\n",
    "            self.row_bn = nn.BatchNorm2d(self.ch_dim)\n",
    "            #row-wise conv is realized by group conv\n",
    "            self.row_conv_group = nn.Conv2d(\n",
    "                 self.ch_dim, 4*self.ch_dim, \n",
    "                 kernel_size=(self.ch_dim, 1), \n",
    "                 groups = self.ch_dim, bias=True)\n",
    "            self.fc_adapt_channels = nn.Conv2d(\n",
    "                 4*self.ch_dim, planes * self.expansion, \n",
    "                 kernel_size=1, groups=1, bias=True)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        if attention in {'2','+','M','&'}:\n",
    "            self.sp_d = att_dim\n",
    "            self.sp_h = 8\n",
    "            self.sp_w = 8\n",
    "            self.sp_reso = self.sp_h * self.sp_w\n",
    "            self.conv_for_DR_spatial = nn.Conv2d(\n",
    "                 planes * self.expansion, self.sp_d, \n",
    "                 kernel_size=1,stride=1, bias=True)\n",
    "            self.bn_for_DR_spatial = nn.BatchNorm2d(self.sp_d)\n",
    "\n",
    "            self.adppool = nn.AdaptiveAvgPool2d((self.sp_h,self.sp_w))\n",
    "            self.row_bn_for_spatial = nn.BatchNorm2d(self.sp_reso)\n",
    "            #row-wise conv is realized by group conv\n",
    "            self.row_conv_group_for_spatial = nn.Conv2d( \n",
    "                 self.sp_reso, self.sp_reso*4, kernel_size=(self.sp_reso, 1), \n",
    "                 groups=self.sp_reso, bias=True)\n",
    "            self.fc_adapt_channels_for_spatial = nn.Conv2d(\n",
    "                 self.sp_reso*4, self.sp_reso, kernel_size=1, groups=1, bias=True)\n",
    "            self.sigmoid = nn.Sigmoid()\n",
    "            self.adpunpool = F.adaptive_avg_pool2d\n",
    "\n",
    "        if attention is '&':#we employ a weighted spatial concat to keep dim\n",
    "            self.groups_base = 32\n",
    "            self.groups = int(planes * self.expansion / 64)\n",
    "            self.factor = int(math.log(self.groups_base / self.groups, 2))\n",
    "            self.padding_num = self.factor + 2\n",
    "            self.conv_kernel_size = self.factor * 2 + 5\n",
    "            self.dilate_conv_for_concat1 = nn.Conv2d(planes * self.expansion, \n",
    "                                                    planes * self.expansion, \n",
    "                                                    kernel_size=(self.conv_kernel_size,1), \n",
    "                                                    stride=1, padding=(self.padding_num,0),\n",
    "                                                    groups=self.groups, bias=True)\n",
    "            self.dilate_conv_for_concat2 = nn.Conv2d(planes * self.expansion, \n",
    "                                                    planes * self.expansion, \n",
    "                                                    kernel_size=(self.conv_kernel_size,1), \n",
    "                                                    stride=1, padding=(self.padding_num,0),\n",
    "                                                    groups=self.groups, bias=True)\n",
    "            self.bn_for_concat = nn.BatchNorm2d(planes * self.expansion)\n",
    "\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.attention = attention\n",
    "\n",
    "    def chan_att(self, out):\n",
    "        # NxCxHxW\n",
    "        out = self.relu_normal(out)\n",
    "        out = self.conv_for_DR(out)\n",
    "        out = self.bn_for_DR(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = MPNCOV.CovpoolLayer(out) # Nxdxd\n",
    "        out = out.view(out.size(0), out.size(1), out.size(2), 1).contiguous() # Nxdxdx1\n",
    "\n",
    "        out = self.row_bn(out)\n",
    "        out = self.row_conv_group(out) # Nx512x1x1\n",
    "\n",
    "        out = self.fc_adapt_channels(out) #NxCx1x1\n",
    "        out = self.sigmoid(out) #NxCx1x1\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def pos_att(self, out):\n",
    "        pre_att = out # NxCxHxW\n",
    "        out = self.relu_normal(out)\n",
    "        out = self.conv_for_DR_spatial(out)\n",
    "        out = self.bn_for_DR_spatial(out)\n",
    "\n",
    "        out = self.adppool(out) # keep the feature map size to 8x8\n",
    "\n",
    "        out = cov_feature(out) # Nx64x64\n",
    "        out = out.view(out.size(0), out.size(1), out.size(2), 1).contiguous()  # Nx64x64x1\n",
    "        out = self.row_bn_for_spatial(out)\n",
    "\n",
    "        out = self.row_conv_group_for_spatial(out) # Nx256x1x1\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.fc_adapt_channels_for_spatial(out) #Nx64x1x1\n",
    "        out = self.sigmoid(out) \n",
    "        out = out.view(out.size(0), 1, self.sp_h, self.sp_w).contiguous()#Nx1x8x8\n",
    "\n",
    "        out = self.adpunpool(out,(pre_att.size(2), pre_att.size(3))) # unpool Nx1xHxW\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "        if self.attention is '1': #channel attention,GSoP default mode\n",
    "            pre_att = out\n",
    "            att = self.chan_att(out)\n",
    "            out = pre_att * att\n",
    "\n",
    "        elif self.attention is '2': #position attention\n",
    "            pre_att = out\n",
    "            att = self.pos_att(out)\n",
    "            out = self.relu_normal(pre_att * att)\n",
    "\n",
    "        elif self.attention is '+': #fusion manner: average\n",
    "            pre_att = out\n",
    "            chan_att = self.chan_att(out)\n",
    "            pos_att = self.pos_att(out)\n",
    "            out = pre_att * chan_att + self.relu(pre_att.clone() * pos_att)\n",
    "\n",
    "        elif self.attention is 'M': #fusion manner: MAX\n",
    "            pre_att = out\n",
    "            chan_att = self.chan_att(out)\n",
    "            pos_att = self.pos_att(out)\n",
    "            out = torch.max(pre_att * chan_att, self.relu(pre_att.clone() * pos_att))\n",
    "\n",
    "        elif self.attention is '&': #fusion manner: concat\n",
    "            pre_att = out\n",
    "            chan_att = self.chan_att(out)\n",
    "            pos_att = self.pos_att(out)\n",
    "            out1 = self.dilate_conv_for_concat1(pre_att * chan_att)\n",
    "            out2 = self.dilate_conv_for_concat2(self.relu(pre_att * pos_att))\n",
    "            out = out1 + out2\n",
    "            out = self.bn_for_concat(out)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, att_position, att_dim, GSoP_mode, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        self.GSoP_mode = GSoP_mode\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], att_position=att_position[0], att_dim=att_dim)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, att_position=att_position[1], att_dim=att_dim)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, att_position=att_position[2], att_dim=att_dim)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, att_position=att_position[3], att_dim=att_dim)\n",
    "        if GSoP_mode == 1:\n",
    "            self.avgpool = nn.AvgPool2d(14, stride=1)\n",
    "            self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "            print(\"GSoP-Net1 generating...\")\n",
    "        else :\n",
    "            self.isqrt_dim = 256\n",
    "            self.layer_reduce = nn.Conv2d(512 * block.expansion, self.isqrt_dim, kernel_size=1, stride=1, padding=0,\n",
    "                                          bias=False)\n",
    "            self.layer_reduce_bn = nn.BatchNorm2d(self.isqrt_dim)\n",
    "            self.layer_reduce_relu = nn.ReLU(inplace=True)\n",
    "            self.fc = nn.Linear(int(self.isqrt_dim * (self.isqrt_dim + 1) / 2), num_classes)\n",
    "            print(\"GSoP-Net2 generating...\")\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, att_position=[1], att_dim=128):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, att_position[0], att_dim=att_dim))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, attention=att_position[i], att_dim=att_dim))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        if self.GSoP_mode == 1:\n",
    "            x = self.avgpool(x)\n",
    "        else :\n",
    "            x = self.layer_reduce(x)\n",
    "            x = self.layer_reduce_bn(x)\n",
    "            x = self.layer_reduce_relu(x)\n",
    "\n",
    "            x = MPNCOV.CovpoolLayer(x)\n",
    "            x = MPNCOV.SqrtmLayer(x, 3)\n",
    "            x = MPNCOV.TriuvecLayer(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, att_position=[[],[],[],[]], att_dim = 128,**kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], att_position, att_dim, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, att_position=[[],[],[],[]], att_dim = 128, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], att_position, att_dim, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Function\n",
    "\n",
    "class Covpool(Function):\n",
    "     @staticmethod\n",
    "     def forward(ctx, input):\n",
    "         x = input\n",
    "         batchSize = x.data.shape[0]\n",
    "         dim = x.data.shape[1]\n",
    "         h = x.data.shape[2]\n",
    "         w = x.data.shape[3]\n",
    "         M = h*w\n",
    "         x = x.reshape(batchSize,dim,M) # b,c,h*W\n",
    "         I_hat = (-1./M/M)*torch.ones(M,M,device = x.device) + (1./M)*torch.eye(M,M,device = x.device)\n",
    "         I_hat = I_hat.view(1,M,M).repeat(batchSize,1,1).type(x.dtype)\n",
    "         y = x.bmm(I_hat).bmm(x.transpose(1,2))\n",
    "         ctx.save_for_backward(input,I_hat)\n",
    "         return y\n",
    "     @staticmethod\n",
    "     def backward(ctx, grad_output):\n",
    "         input,I_hat = ctx.saved_tensors\n",
    "         x = input\n",
    "         batchSize = x.data.shape[0]\n",
    "         dim = x.data.shape[1]\n",
    "         h = x.data.shape[2]\n",
    "         w = x.data.shape[3]\n",
    "         M = h*w\n",
    "         x = x.reshape(batchSize,dim,M)\n",
    "         grad_input = grad_output + grad_output.transpose(1,2)\n",
    "         grad_input = grad_input.bmm(x).bmm(I_hat)\n",
    "         grad_input = grad_input.reshape(batchSize,dim,h,w)\n",
    "         return grad_input\n",
    "\n",
    "class Sqrtm(Function):\n",
    "     @staticmethod\n",
    "     def forward(ctx, input, iterN):\n",
    "         x = input\n",
    "         batchSize = x.data.shape[0]\n",
    "         dim = x.data.shape[1]\n",
    "         dtype = x.dtype\n",
    "         I3 = 3.0*torch.eye(dim,dim,device = x.device).view(1, dim, dim).repeat(batchSize,1,1).type(dtype)\n",
    "         normA = (1.0/3.0)*x.mul(I3).sum(dim=1).sum(dim=1)\n",
    "         A = x.div(normA.view(batchSize,1,1).expand_as(x))\n",
    "         Y = torch.zeros(batchSize, iterN, dim, dim, requires_grad = False, device = x.device)\n",
    "         Z = torch.eye(dim,dim,device = x.device).view(1,dim,dim).repeat(batchSize,iterN,1,1)\n",
    "         if iterN < 2:\n",
    "            ZY = 0.5*(I3 - A)\n",
    "            Y[:,0,:,:] = A.bmm(ZY)\n",
    "         else:\n",
    "            ZY = 0.5*(I3 - A)\n",
    "            Y[:,0,:,:] = A.bmm(ZY)\n",
    "            Z[:,0,:,:] = ZY\n",
    "            for i in range(1, iterN-1):\n",
    "               ZY = 0.5*(I3 - Z[:,i-1,:,:].bmm(Y[:,i-1,:,:]))\n",
    "               Y[:,i,:,:] = Y[:,i-1,:,:].bmm(ZY)\n",
    "               Z[:,i,:,:] = ZY.bmm(Z[:,i-1,:,:])\n",
    "            ZY = 0.5*Y[:,iterN-2,:,:].bmm(I3 - Z[:,iterN-2,:,:].bmm(Y[:,iterN-2,:,:]))\n",
    "         y = ZY*torch.sqrt(normA).view(batchSize, 1, 1).expand_as(x)\n",
    "         ctx.save_for_backward(input, A, ZY, normA, Y, Z)\n",
    "         ctx.iterN = iterN\n",
    "         return y\n",
    "     @staticmethod\n",
    "     def backward(ctx, grad_output):\n",
    "         input, A, ZY, normA, Y, Z = ctx.saved_tensors\n",
    "         iterN = ctx.iterN\n",
    "         x = input\n",
    "         batchSize = x.data.shape[0]\n",
    "         dim = x.data.shape[1]\n",
    "         dtype = x.dtype\n",
    "         der_postCom = grad_output*torch.sqrt(normA).view(batchSize, 1, 1).expand_as(x)\n",
    "         der_postComAux = (grad_output*ZY).sum(dim=1).sum(dim=1).div(2*torch.sqrt(normA))\n",
    "         I3 = 3.0*torch.eye(dim,dim,device = x.device).view(1, dim, dim).repeat(batchSize,1,1).type(dtype)\n",
    "         if iterN < 2:\n",
    "            der_NSiter = 0.5*(der_postCom.bmm(I3 - A) - A.bmm(der_sacleTrace))\n",
    "         else:\n",
    "            dldY = 0.5*(der_postCom.bmm(I3 - Y[:,iterN-2,:,:].bmm(Z[:,iterN-2,:,:])) -\n",
    "                          Z[:,iterN-2,:,:].bmm(Y[:,iterN-2,:,:]).bmm(der_postCom))\n",
    "            dldZ = -0.5*Y[:,iterN-2,:,:].bmm(der_postCom).bmm(Y[:,iterN-2,:,:])\n",
    "            for i in range(iterN-3, -1, -1):\n",
    "               YZ = I3 - Y[:,i,:,:].bmm(Z[:,i,:,:])\n",
    "               ZY = Z[:,i,:,:].bmm(Y[:,i,:,:])\n",
    "               dldY_ = 0.5*(dldY.bmm(YZ) - \n",
    "                         Z[:,i,:,:].bmm(dldZ).bmm(Z[:,i,:,:]) - \n",
    "                             ZY.bmm(dldY))\n",
    "               dldZ_ = 0.5*(YZ.bmm(dldZ) - \n",
    "                         Y[:,i,:,:].bmm(dldY).bmm(Y[:,i,:,:]) -\n",
    "                            dldZ.bmm(ZY))\n",
    "               dldY = dldY_\n",
    "               dldZ = dldZ_\n",
    "            der_NSiter = 0.5*(dldY.bmm(I3 - A) - dldZ - A.bmm(dldY))\n",
    "         grad_input = der_NSiter.div(normA.view(batchSize,1,1).expand_as(x))\n",
    "         grad_aux = der_NSiter.mul(x).sum(dim=1).sum(dim=1)\n",
    "         for i in range(batchSize):\n",
    "             grad_input[i,:,:] += (der_postComAux[i] \\\n",
    "                                   - grad_aux[i] / (normA[i] * normA[i])) \\\n",
    "                                   *torch.ones(dim,device = x.device).diag()\n",
    "         return grad_input, None\n",
    "\n",
    "class Triuvec(Function):\n",
    "     @staticmethod\n",
    "     def forward(ctx, input):\n",
    "         x = input\n",
    "         batchSize = x.data.shape[0]\n",
    "         dim = x.data.shape[1]\n",
    "         dtype = x.dtype\n",
    "         x = x.reshape(batchSize, dim*dim)\n",
    "         I = torch.ones(dim,dim).triu().t().reshape(dim*dim)\n",
    "         index = I.nonzero()\n",
    "         y = torch.zeros(batchSize,int(dim*(dim+1)/2),device = x.device)\n",
    "         for i in range(batchSize):\n",
    "            y[i, :] = x[i, index].t()\n",
    "         ctx.save_for_backward(input,index)\n",
    "         return y\n",
    "     @staticmethod\n",
    "     def backward(ctx, grad_output):\n",
    "         input,index = ctx.saved_tensors\n",
    "         x = input\n",
    "         batchSize = x.data.shape[0]\n",
    "         dim = x.data.shape[1]\n",
    "         dtype = x.dtype\n",
    "         grad_input = torch.zeros(batchSize,dim,dim,device = x.device,requires_grad=False)\n",
    "         grad_input = grad_input.reshape(batchSize,dim*dim)\n",
    "         for i in range(batchSize):\n",
    "            grad_input[i,index] = grad_output[i,:].reshape(index.size(),1)\n",
    "         grad_input = grad_input.reshape(batchSize,dim,dim)\n",
    "         return grad_input\n",
    "\n",
    "def CovpoolLayer(var):\n",
    "    return Covpool.apply(var)\n",
    "\n",
    "def SqrtmLayer(var, iterN):\n",
    "    return Sqrtm.apply(var, iterN)\n",
    "\n",
    "def TriuvecLayer(var):\n",
    "    return Triuvec.apply(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "620e0971fdfedb47815252a730f9c9fc24e1c5eb66f4c856afd7a9506a291b64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
